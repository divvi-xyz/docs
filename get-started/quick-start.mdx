---
title: Quickstart Guide

icon: terminal

description: Let's get you started with Prem in minutes. In this guide, we'll show you how to use the **Chat Completions** funcationality. 
---
<Note>
This is a quickstart guide for using the **Chat Completions** funcationality. 

Chat completions allow you to choose a model (e.g. `gpt-4o` or the name of a model you fine-tuned) to generate a response using a text-based prompt.

Keep in mind that Prem is designed to make the process of creating custom models easy and efficient. Most of the functionality like fine-tuning, evaluations, stats and playground will be available on the Prem platform. Once you've configured your settings, you'll be able to use your custom models by simply using the [Prem AI API](/api-reference/introduction) or OpenAI SDKs.

If you want to learn about [Datasets](/datasets/overview), [Autonomous Fine-Tuning](/finetuning/overview), [Evaluations](/evaluations/overview), [Stats](/stats/overview) and [Playground](/playground/overview), please refer to those guides.
</Note>


The quickest way to get started with Prem is to use the OpenAI SDKs for chat completions as shown below.

<Note>
You can also use the [Prem AI API](/api-reference/introduction) to generate chat completions. 

With the API you can use any programming language that has a HTTP client.

We give you the option to use the [Prem AI API](/api-reference/introduction) or the OpenAI SDKs.
 
For API usage documentation, refer to the [API Reference](/api-reference/introduction).
</Note>

<Steps>
<Step title="Create an API Key ðŸ”‘">

Click the **API Key** Button on the sidebar. Then click the **+ Create API Key** button. 

Afterwards, copy the API key and save it in a secure location.

<img
  src="https://static.premai.io/prem-saas-docs/get-started/quickstart-guide/create-api-key.gif"
  alt="Create an API Key"
/>



</Step>

<Step title="Install the OpenAI SDKs">
### Install the OpenAI SDKs
<CodeGroup>
```bash javascript/typescript
npm install openai;
```
```bash python
pip install openai;
```
</CodeGroup>
</Step>

<Step title="Perform a Chat Completion">
<Note>
The model name can be replaced with the name of your fine-tuned models as well.
</Note>                      
<CodeGroup>
```javascript javascript/typescript
import OpenAI from "openai";

const client = new OpenAI({
    baseURL: "https://studio.premai.io/api/v1/",
    apiKey: process.env.PREMAI_API_KEY,
});

//Create a chat completion
const response = await client.chat.completions.create({
    model: "gpt-4o", //Or any other model you want to use
    messages: [{ role: "user", content: "Write a one-sentence bedtime story about a unicorn." }]
});

console.log(response.choices[0].message.content);
```
```python python
import os
from openai import OpenAI

client = OpenAI(
    base_url="https://studio.premai.io/api/v1/",
    api_key=os.environ.get("PREMAI_API_KEY"),
)

# Create a chat completion
response = client.chat.completions.create(
    messages=[{"role": "user", "content": "Who won the world series in 2020?"}],
    model="gpt-4o", # Or any other model you want to use
)

print(response.choices[0].message.content)
```
</CodeGroup>

### Chat Completion with Streaming
<CodeGroup>
```javascript javascript/typescript
import OpenAI from "openai";

const client = new OpenAI({
    baseURL: "https://studio.premai.io/api/v1/",
    apiKey: process.env.PREMAI_API_KEY,
});

//Create a chat completion
const response = await client.chat.completions.create({
    model: "gpt-4o", //Or any other model you want to use
    messages: [{ role: "user", content: "Write a one-sentence bedtime story about a unicorn." }],
    stream: true,
});

for await (const chunk of response) {
    if (chunk.choices[0].delta.content) {
        process.stdout.write(chunk.choices[0].delta.content);
        
    }
}
```
```python python
import os
from openai import OpenAI

client = OpenAI(
    base_url="https://studio.premai.io/api/v1/",
    api_key=os.environ.get("PREMAI_API_KEY"),
)

# Create completion
response = client.chat.completions.create(
    messages=[{"role": "user", "content": "Who won the world series in 2020?"}],
    model="gpt-4o", # Or any other model you want to use
    stream=True,
)

for chunk in response:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end='', flush=True)
```
</CodeGroup>
</Step>
</Steps>



## Next steps

- Add your own [Dataset](/datasets/overview) as a first step to create your own custom models.
- Next, [Autonomously Fine-Tune](/finetuning/overview) your models using a dataset.
- Then, use [Evaluations](/evaluations/overview) to track your models performance.
- Afterwards, keep up with your model's performance with [Stats](/stats/overview).
- Finally, test models your fine-tuned models and pre-trained models in the [Playground](/playground/overview).
- Bring your models to production or repeat any steps you need to improve your models or make new ones.

## Read the guides

<CardGroup cols={3}>
<Card title="Datasets" icon="database" href="/datasets/overview">
  Import your own dataset.
</Card>


<Card title="Autonomous Fine-Tuning" icon="robot" href="/finetuning/overview">
    Fine-Tune your models.
</Card>

{" "}

<Card title="Evaluations" icon="heart-pulse" href="/evaluations/overview">
    Evaluate your models.
</Card>

</CardGroup>

<CardGroup cols={3}>
  <Card title="Playground" icon="play" href="/playground/overview">
    Experiment with AI models.
  </Card>
  <Card title="Stats" icon="chart-line" href="/stats/overview">
    Monitor your AI integration.
  </Card>
  <Card title="API" icon="code" href="/api-reference/introduction">
    Use the Prem API.
  </Card>
</CardGroup>
----
## Support
<CardGroup cols={2}>
  <Card title="FAQ" icon="question" href="/resources/faq">
    Find answers to frequently asked questions about Prem.
  </Card>
  <Card title="Available Models" icon="plus" href="/resources/available-models">
  See the list of available models in Prem.
  </Card>
</CardGroup>

